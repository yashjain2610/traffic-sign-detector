{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Tdykik2JI5x0"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "from sklearn.model_selection import train_test_split\n",
        "import random\n",
        "import torch\n",
        "from torchvision import transforms\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchinfo\n",
        "from torchinfo import summary\n",
        "from tqdm.auto import tqdm\n",
        "import torch.optim as optim\n",
        "import pickle\n",
        "\n",
        "path = \"Data\"\n",
        "labelFile = \"labels.csv\"\n",
        "BATCH_SIZE = 20\n",
        "epochs = 1\n",
        "steps_per_epoch = 2000\n",
        "imageDimensions = (32,32,3)\n",
        "test_ratio = 0.2\n",
        "validation_ratio = 0.2\n",
        "\n",
        "#import images\n",
        "\n",
        "cnt = 0\n",
        "images = []\n",
        "classno = []\n",
        "list_data = os.listdir(path)\n",
        "print(len(list_data))\n",
        "no_of_classes = len(list_data)\n",
        "\n",
        "for i in range(no_of_classes):\n",
        "    pic_list = os.listdir(path+\"/\"+str(cnt))\n",
        "    for pic in pic_list:\n",
        "        pic_path = path+\"/\"+str(cnt)+\"/\"+pic\n",
        "        img = cv2.imread(pic_path)\n",
        "        images.append(img)\n",
        "        classno.append(cnt)\n",
        "    print(cnt)\n",
        "    cnt += 1\n",
        "\n",
        "images = np.array(images)\n",
        "classno = np.array(classno)\n",
        "print(images.shape)\n",
        "print(classno.shape)\n",
        "\n",
        "#split data\n",
        "X_train, X_test, y_train, y_test = train_test_split(images, classno, test_size=test_ratio)\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=validation_ratio)\n",
        "print(X_train.shape)\n",
        "print(X_test.shape)\n",
        "print(X_val.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JhwcPgNGK9p6"
      },
      "outputs": [],
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XHTSZjyxI5x2"
      },
      "outputs": [],
      "source": [
        "data = pd.read_csv(labelFile)\n",
        "print(data.shape)\n",
        "print(data.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UlHE0JStI5x2"
      },
      "outputs": [],
      "source": [
        "num_of_samples = []\n",
        "cols = 5\n",
        "num_classes = no_of_classes\n",
        "\n",
        "fig, axs = plt.subplots(nrows=num_classes, ncols=cols, figsize=(5,50))\n",
        "fig.tight_layout()\n",
        "for i in range(cols):\n",
        "    for j,row in data.iterrows():\n",
        "        x_selected = X_train[y_train == j]\n",
        "        axs[j][i].imshow(x_selected[np.random.randint(0,len(x_selected)) - 1,:,:], cmap=\"gray\")\n",
        "        axs[j][i].axis(\"off\")\n",
        "        if i==2:\n",
        "            axs[j][i].set_title(str(j)+ \"-\" + row[\"Name\"])\n",
        "            num_of_samples.append(len(x_selected))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XKDHp7h_I5x2"
      },
      "outputs": [],
      "source": [
        "print(num_of_samples)\n",
        "plt.figure(figsize=(12,4))\n",
        "plt.bar(range(0,num_classes), num_of_samples)\n",
        "plt.title(\"Distribution of the training data\")\n",
        "plt.xlabel(\"Class number\")\n",
        "plt.ylabel(\"Number of images\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-BG-Y7ouI5x2"
      },
      "outputs": [],
      "source": [
        "def grayscale(img):\n",
        "    img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "    return img\n",
        "def equalize(img):\n",
        "    img = cv2.equalizeHist(img)\n",
        "    return img\n",
        "def preprocessing(img):\n",
        "    img = grayscale(img)\n",
        "    img = equalize(img)\n",
        "    img = img/255\n",
        "    return img\n",
        "\n",
        "X_train = np.array(list(map(preprocessing, X_train)))\n",
        "X_val = np.array(list(map(preprocessing, X_val)))\n",
        "X_test = np.array(list(map(preprocessing,X_test)))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d9HRIx40I5x3"
      },
      "outputs": [],
      "source": [
        "X_train = X_train.reshape(X_train.shape[0], X_train.shape[1], X_train.shape[2], 1)\n",
        "X_val = X_val.reshape(X_val.shape[0], X_val.shape[1], X_val.shape[2], 1)\n",
        "X_test = X_test.reshape(X_test.shape[0],X_test.shape[1],X_test.shape[2],1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z0arEzKQI5x3"
      },
      "outputs": [],
      "source": [
        "plt.imshow(X_train[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OT4zqDvxI5x3"
      },
      "outputs": [],
      "source": [
        "data_transforms = transforms.Compose([\n",
        "    transforms.RandomAffine(\n",
        "        degrees=10,\n",
        "        translate=(0.1, 0.1),\n",
        "        scale=(0.8, 1.2),\n",
        "        shear=10\n",
        "    ),\n",
        "    transforms.ToTensor()\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JwU5OAQPI5x3"
      },
      "outputs": [],
      "source": [
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, images, labels, transform=None):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            images (numpy.ndarray): Image data (N, H, W, C).\n",
        "            labels (numpy.ndarray): Corresponding labels (N,).\n",
        "            transform (callable, optional): Optional transform to be applied on an image.\n",
        "        \"\"\"\n",
        "        self.images = images\n",
        "        self.labels = labels\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.images)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image = self.images[idx]\n",
        "        label = self.labels[idx]\n",
        "\n",
        "        # Convert NumPy image (H, W, C) to PIL image for transformation\n",
        "        image = transforms.ToPILImage()(image)\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        return image, label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qa7HMYEGI5x3"
      },
      "outputs": [],
      "source": [
        "X_train_dataset = CustomDataset(X_train, y_train, transform=data_transforms)\n",
        "X_val_dataset = CustomDataset(X_val, y_val,transform=data_transforms)\n",
        "X_test_dataset = CustomDataset(X_test, y_test)\n",
        "\n",
        "X_train_loader = DataLoader(X_train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "X_val_loader = DataLoader(X_val_dataset, batch_size=BATCH_SIZE)\n",
        "X_test_loader = DataLoader(X_test_dataset, batch_size=BATCH_SIZE)\n",
        "\n",
        "X_train_dataset[3478][0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "16gBD_x5I5x3"
      },
      "outputs": [],
      "source": [
        "fig,axs=plt.subplots(2,15,figsize=(20,5))\n",
        "fig.tight_layout()\n",
        "\n",
        "for i in range(15):\n",
        "    axs[0][i].imshow(X_train_dataset[i][0].numpy().reshape(32,32,1))\n",
        "    axs[1][i].set_title(X_train_dataset[i][1])\n",
        "    axs[0][i].axis('off')\n",
        "    axs[1][i].axis('off')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t7BEJ4OrI5x3"
      },
      "outputs": [],
      "source": [
        "class MyModel(nn.Module):\n",
        "    def __init__(self,input_shape,num_classes):\n",
        "        super(MyModel, self).__init__()\n",
        "        no_of_filters = 60\n",
        "        size_of_filter = (5,5)\n",
        "        size_of_filter2 = (3,3)\n",
        "        size_of_pool = (2,2)\n",
        "        no_of_nodes = 500\n",
        "\n",
        "        self.conv1 = nn.Conv2d(in_channels = 1, out_channels = no_of_filters, kernel_size = size_of_filter)\n",
        "        self.conv2 = nn.Conv2d(in_channels = no_of_filters, out_channels = no_of_filters, kernel_size = size_of_filter)\n",
        "        self.pool1 = nn.MaxPool2d(kernel_size = size_of_pool)\n",
        "\n",
        "        self.conv3 = nn.Conv2d(in_channels = no_of_filters, out_channels = no_of_filters//2, kernel_size = size_of_filter2)\n",
        "        self.conv4 = nn.Conv2d(in_channels = no_of_filters//2, out_channels = no_of_filters//2, kernel_size = size_of_filter2)\n",
        "        self.pool2 = nn.MaxPool2d(kernel_size = size_of_pool)\n",
        "\n",
        "        self.flat = nn.Flatten()\n",
        "\n",
        "        self.fc1 = nn.Linear(self.get_flatten_shape(input_shape), no_of_nodes)\n",
        "        self.fc2 = nn.Linear(no_of_nodes, num_classes)\n",
        "\n",
        "        self.dropout = nn.Dropout(p=0.5)\n",
        "\n",
        "    def get_flatten_shape(self, input_shape):\n",
        "        dummy_input = torch.zeros(1, 1, input_shape[2], input_shape[3])\n",
        "        x = self.pool1(self.conv2(self.conv1(dummy_input)))\n",
        "        x = self.pool2(self.conv4(self.conv3(x)))\n",
        "        return x.numel()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.conv1(x))\n",
        "        x = F.relu(self.conv2(x))\n",
        "        x = self.pool1(x)\n",
        "\n",
        "        x = F.relu(self.conv3(x))\n",
        "        x = F.relu(self.conv4(x))\n",
        "        x = self.pool2(x)\n",
        "        x = self.dropout(x)\n",
        "\n",
        "        x = F.relu(self.fc1(self.flat(x)))\n",
        "        x = self.dropout(x)\n",
        "        x = self.fc2(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SRKBnuaDI5x3"
      },
      "outputs": [],
      "source": [
        "input_shape = X_train_dataset[0][0].shape\n",
        "num_classes = no_of_classes\n",
        "model = MyModel(input_shape=[1,1,32,32], num_classes=num_classes).to(device)\n",
        "model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S3J5u4WCI5x4"
      },
      "outputs": [],
      "source": [
        "img_batch, label_batch = next(iter(X_train_loader))\n",
        "print(f\"Image batch shape: {img_batch.shape}\\n\")\n",
        "print(f\"Label batch shape: {label_batch.shape}\")\n",
        "# 2. Get a single image from the batch and unsqueeze the image so its shape fits the model\n",
        "img_single, label_single = img_batch[0].unsqueeze(dim=0), label_batch[0]\n",
        "print(f\"Single image shape: {img_single.shape}\\n\")\n",
        "\n",
        "# 3. Perform a forward pass on a single image\n",
        "model.eval()\n",
        "with torch.inference_mode():\n",
        "    pred = model(img_single.to(device))\n",
        "\n",
        "# 4.convert model logits -> pred probs -> pred label\n",
        "print(f\"Output logits:\\n{pred}\\n\")\n",
        "print(f\"Output prediction probabilities:\\n{torch.softmax(pred, dim=1)}\\n\")\n",
        "print(f\"Output prediction label:\\n{torch.argmax(torch.softmax(pred, dim=1), dim=1)}\\n\")\n",
        "print(f\"Actual label:\\n{label_single}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MiJuyRNzI5x4"
      },
      "outputs": [],
      "source": [
        "summary(model, input_size = [1,1,32,32])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qQXRRT4KI5x4"
      },
      "outputs": [],
      "source": [
        "def train_step(model: torch.nn.Module,\n",
        "               dataloader: torch.utils.data.DataLoader,\n",
        "               loss_fn: torch.nn.Module,\n",
        "               optimizer: torch.optim.Optimizer):\n",
        "    # Put model in train mode\n",
        "    model.train()\n",
        "\n",
        "    # Setup train loss and train accuracy values\n",
        "    train_loss, train_acc = 0, 0\n",
        "\n",
        "    # Loop through data loader data batches\n",
        "    for batch, (X, y) in enumerate(dataloader):\n",
        "        # Send data to target device\n",
        "        X, y = X.to(device), y.to(device)\n",
        "\n",
        "        # 1. Forward pass\n",
        "        y_pred = model(X)\n",
        "\n",
        "        # 2. Calculate  and accumulate loss\n",
        "        loss = loss_fn(y_pred, y)\n",
        "        train_loss += loss.item()\n",
        "\n",
        "        # 3. Optimizer zero grad\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # 4. Loss backward\n",
        "        loss.backward()\n",
        "\n",
        "        # 5. Optimizer step\n",
        "        optimizer.step()\n",
        "\n",
        "        # Calculate and accumulate accuracy metrics across all batches\n",
        "        y_pred_class = torch.argmax(torch.softmax(y_pred, dim=1), dim=1)\n",
        "        train_acc += (y_pred_class == y).sum().item()/len(y_pred)\n",
        "\n",
        "    # Adjust metrics to get average loss and accuracy per batch\n",
        "    train_loss = train_loss / len(dataloader)\n",
        "    train_acc = train_acc / len(dataloader)\n",
        "    return train_loss, train_acc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NN2cEdy7YDiA"
      },
      "outputs": [],
      "source": [
        "def test_step(model: torch.nn.Module,\n",
        "              dataloader: torch.utils.data.DataLoader,\n",
        "              loss_fn: torch.nn.Module):\n",
        "    # Put model in eval mode\n",
        "    model.eval()\n",
        "\n",
        "    # Setup test loss and test accuracy values\n",
        "    test_loss, test_acc = 0, 0\n",
        "\n",
        "    # Turn on inference context manager\n",
        "    with torch.inference_mode():\n",
        "        # Loop through DataLoader batches\n",
        "        for batch, (X, y) in enumerate(dataloader):\n",
        "            # Send data to target device\n",
        "            X, y = X.to(device), y.to(device)\n",
        "\n",
        "            # 1. Forward pass\n",
        "            test_pred_logits = model(X)\n",
        "\n",
        "            # 2. Calculate and accumulate loss\n",
        "            loss = loss_fn(test_pred_logits, y)\n",
        "            test_loss += loss.item()\n",
        "\n",
        "            # Calculate and accumulate accuracy\n",
        "            test_pred_labels = test_pred_logits.argmax(dim=1)\n",
        "            test_acc += ((test_pred_labels == y).sum().item()/len(test_pred_labels))\n",
        "\n",
        "    # Adjust metrics to get average loss and accuracy per batch\n",
        "    test_loss = test_loss / len(dataloader)\n",
        "    test_acc = test_acc / len(dataloader)\n",
        "    return test_loss, test_acc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mK1n5DwhYsyY"
      },
      "outputs": [],
      "source": [
        "# 1. Take in various parameters required for training and test steps\n",
        "def train(model: torch.nn.Module,\n",
        "          train_dataloader: torch.utils.data.DataLoader,\n",
        "          test_dataloader: torch.utils.data.DataLoader,\n",
        "          optimizer: torch.optim.Optimizer,\n",
        "          loss_fn: torch.nn.Module = nn.CrossEntropyLoss(),\n",
        "          epochs: int = 5):\n",
        "\n",
        "    # 2. Create empty results dictionary\n",
        "    results = {\"train_loss\": [],\n",
        "        \"train_acc\": [],\n",
        "        \"test_loss\": [],\n",
        "        \"test_acc\": []\n",
        "    }\n",
        "\n",
        "    # 3. Loop through training and testing steps for a number of epochs\n",
        "    for epoch in tqdm(range(epochs)):\n",
        "        train_loss, train_acc = train_step(model=model,\n",
        "                                           dataloader=train_dataloader,\n",
        "                                           loss_fn=loss_fn,\n",
        "                                           optimizer=optimizer)\n",
        "        test_loss, test_acc = test_step(model=model,\n",
        "            dataloader=test_dataloader,\n",
        "            loss_fn=loss_fn)\n",
        "\n",
        "        # 4. Print out what's happening\n",
        "        print(\n",
        "            f\"Epoch: {epoch+1} | \"\n",
        "            f\"train_loss: {train_loss:.4f} | \"\n",
        "            f\"train_acc: {train_acc:.4f} | \"\n",
        "            f\"test_loss: {test_loss:.4f} | \"\n",
        "            f\"test_acc: {test_acc:.4f}\"\n",
        "        )\n",
        "\n",
        "        # 5. Update results dictionary\n",
        "        # Ensure all data is moved to CPU and converted to float for storage\n",
        "        results[\"train_loss\"].append(train_loss.item() if isinstance(train_loss, torch.Tensor) else train_loss)\n",
        "        results[\"train_acc\"].append(train_acc.item() if isinstance(train_acc, torch.Tensor) else train_acc)\n",
        "        results[\"test_loss\"].append(test_loss.item() if isinstance(test_loss, torch.Tensor) else test_loss)\n",
        "        results[\"test_acc\"].append(test_acc.item() if isinstance(test_acc, torch.Tensor) else test_acc)\n",
        "\n",
        "    # 6. Return the filled results at the end of the epochs\n",
        "    return results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sNXbJEJvZJeo"
      },
      "outputs": [],
      "source": [
        "# Define loss and optimizer\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(params = model.parameters(), lr=0.001)\n",
        "\n",
        "# pickle_in=open(\"model_trained.p\",\"rb\")\n",
        "# model=pickle.load(pickle_in)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7aNuKW2LcMRh"
      },
      "outputs": [],
      "source": [
        "results = train(model = model, train_dataloader=X_train_loader, test_dataloader=X_val_loader,optimizer = optimizer, loss_fn=loss_fn,epochs=15)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NW4znQagdK9k"
      },
      "outputs": [],
      "source": [
        "def plot_loss_curves(results):\n",
        "    \"\"\"Plots training curves of a results dictionary.\n",
        "\n",
        "    Args:\n",
        "        results (dict): dictionary containing list of values, e.g.\n",
        "            {\"train_loss\": [...],\n",
        "             \"train_acc\": [...],\n",
        "             \"test_loss\": [...],\n",
        "             \"test_acc\": [...]}\n",
        "    \"\"\"\n",
        "\n",
        "    # Get the loss values of the results dictionary (training and test)\n",
        "    loss = results['train_loss']\n",
        "    test_loss = results['test_loss']\n",
        "\n",
        "    # Get the accuracy values of the results dictionary (training and test)\n",
        "    accuracy = results['train_acc']\n",
        "    test_accuracy = results['test_acc']\n",
        "\n",
        "    # Figure out how many epochs there were\n",
        "    epochs = range(len(results['train_loss']))\n",
        "\n",
        "    # Setup a plot\n",
        "    plt.figure(figsize=(15, 7))\n",
        "\n",
        "    # Plot loss\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(epochs, loss, label='train_loss')\n",
        "    plt.plot(epochs, test_loss, label='test_loss')\n",
        "    plt.title('Loss')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.legend()\n",
        "\n",
        "    # Plot accuracy\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.plot(epochs, accuracy, label='train_accuracy')\n",
        "    plt.plot(epochs, test_accuracy, label='test_accuracy')\n",
        "    plt.title('Accuracy')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.legend()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WzdObcP2Vq2R"
      },
      "outputs": [],
      "source": [
        "plot_loss_curves(results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9fk7IKCkXOBf"
      },
      "source": [
        "Save and Test the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UAyMjq-jaUxq"
      },
      "outputs": [],
      "source": [
        "torch.save(model.state_dict(), \"model_trained.pth\")\n",
        "cv2.waitKey(0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q2sdxH48dRBi"
      },
      "outputs": [],
      "source": [
        "frameWidth= 640         # CAMERA RESOLUTION\n",
        "frameHeight = 480\n",
        "brightness = 180\n",
        "threshold = 0.9        # PROBABLITY THRESHOLD\n",
        "font = cv2.FONT_HERSHEY_SIMPLEX"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MAbVbHBbc44O"
      },
      "outputs": [],
      "source": [
        "cap = cv2.VideoCapture(0)\n",
        "cap.set(3, frameWidth)\n",
        "cap.set(4, frameHeight)\n",
        "cap.set(10, brightness)\n",
        "# IMPORT THE TRANNIED MODEL\n",
        "model = MyModel(input_shape=[1,1,32,32], num_classes=num_classes).to(device)\n",
        "model.load_state_dict(torch.load(\"model_trained.pth\", map_location=device))\n",
        "model.to(device)\n",
        "model.eval()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YaFruYzvdJfd"
      },
      "outputs": [],
      "source": [
        "def getClassName(classNo):\n",
        "  if   classNo == 0: return 'Speed Limit 20 km/h'\n",
        "  elif classNo == 1: return 'Speed Limit 30 km/h'\n",
        "  elif classNo == 2: return 'Speed Limit 50 km/h'\n",
        "  elif classNo == 3: return 'Speed Limit 60 km/h'\n",
        "  elif classNo == 4: return 'Speed Limit 70 km/h'\n",
        "  elif classNo == 5: return 'Speed Limit 80 km/h'\n",
        "  elif classNo == 6: return 'End of Speed Limit 80 km/h'\n",
        "  elif classNo == 7: return 'Speed Limit 100 km/h'\n",
        "  elif classNo == 8: return 'Speed Limit 120 km/h'\n",
        "  elif classNo == 9: return 'No passing'\n",
        "  elif classNo == 10: return 'No passing for vechiles over 3.5 metric tons'\n",
        "  elif classNo == 11: return 'Right-of-way at the next intersection'\n",
        "  elif classNo == 12: return 'Priority road'\n",
        "  elif classNo == 13: return 'Yield'\n",
        "  elif classNo == 14: return 'Stop'\n",
        "  elif classNo == 15: return 'No vechiles'\n",
        "  elif classNo == 16: return 'Vechiles over 3.5 metric tons prohibited'\n",
        "  elif classNo == 17: return 'No entry'\n",
        "  elif classNo == 18: return 'General caution'\n",
        "  elif classNo == 19: return 'Dangerous curve to the left'\n",
        "  elif classNo == 20: return 'Dangerous curve to the right'\n",
        "  elif classNo == 21: return 'Double curve'\n",
        "  elif classNo == 22: return 'Bumpy road'\n",
        "  elif classNo == 23: return 'Slippery road'\n",
        "  elif classNo == 24: return 'Road narrows on the right'\n",
        "  elif classNo == 25: return 'Road work'\n",
        "  elif classNo == 26: return 'Traffic signals'\n",
        "  elif classNo == 27: return 'Pedestrians'\n",
        "  elif classNo == 28: return 'Children crossing'\n",
        "  elif classNo == 29: return 'Bicycles crossing'\n",
        "  elif classNo == 30: return 'Beware of ice/snow'\n",
        "  elif classNo == 31: return 'Wild animals crossing'\n",
        "  elif classNo == 32: return 'End of all speed and passing limits'\n",
        "  elif classNo == 33: return 'Turn right ahead'\n",
        "  elif classNo == 34: return 'Turn left ahead'\n",
        "  elif classNo == 35: return 'Ahead only'\n",
        "  elif classNo == 36: return 'Go straight or right'\n",
        "  elif classNo == 37: return 'Go straight or left'\n",
        "  elif classNo == 38: return 'Keep right'\n",
        "  elif classNo == 39: return 'Keep left'\n",
        "  elif classNo == 40: return 'Roundabout mandatory'\n",
        "  elif classNo == 41: return 'End of no passing'\n",
        "  elif classNo == 42: return 'End of no passing by vechiles over 3.5 metric tons'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MFScr7bDdZ9e"
      },
      "outputs": [],
      "source": [
        "while True:\n",
        "    success, imgOriginal = cap.read()\n",
        "    if not success:\n",
        "        print(\"Error: Could not read frame from camera.\")\n",
        "        break\n",
        "\n",
        "    img = cv2.resize(imgOriginal, (32, 32))\n",
        "    img = preprocessing(img)\n",
        "    img = img.reshape(1, 1, 32, 32)\n",
        "    img = torch.from_numpy(img).float().to(device)\n",
        "\n",
        "    with torch.inference_mode():\n",
        "        outputs = model(img)\n",
        "        classIndex = torch.argmax(outputs, dim=1).item()\n",
        "        probabilityValue = torch.max(torch.softmax(outputs, dim=1)).item()\n",
        "\n",
        "    cv2.putText(imgOriginal, \"CLASS:\", (20, 35), font, 0.75, (0, 0, 255), 2, cv2.LINE_AA)\n",
        "    cv2.putText(imgOriginal, \"PROBABILITY:\", (20, 75), font, 0.75, (0, 0, 255), 2, cv2.LINE_AA)\n",
        "\n",
        "    if probabilityValue > threshold:\n",
        "        cv2.putText(imgOriginal, f\"{classIndex} {getClassName(classIndex)}\", (120, 35), font, 0.75, (0, 0, 255), 2, cv2.LINE_AA)\n",
        "        cv2.putText(imgOriginal, f\"{round(probabilityValue * 100, 2)}%\", (180, 75), font, 0.75, (0, 0, 255), 2, cv2.LINE_AA)\n",
        "\n",
        "    cv2.imshow(\"Result\", imgOriginal)\n",
        "\n",
        "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
        "        break\n",
        "\n",
        "cap.release()\n",
        "cv2.destroyAllWindows()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hRO2L-3nXOBh"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LJmjXSjBXOBh"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}